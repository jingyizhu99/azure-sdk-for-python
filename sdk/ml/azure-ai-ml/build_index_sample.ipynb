{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this example\n",
    "This sample shows how to create an index on the cloud with Azure AI resources.\n",
    "\n",
    "This sample is useful for developers and data scientists who wish to use their data to create an Index which can be used in the RAG pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"<subscription_id>\"\n",
    "resource_group = \"<resource_group>\"\n",
    "workspace = \"<workspace>\"\n",
    "\n",
    "index_name = \"<your_index_name>\"\n",
    "\n",
    "# change model name and deployment name if it's different from yours\n",
    "# don't need these if you are using serverless models\n",
    "embedding_model_name = \"text-embedding-ada-002\"\n",
    "embedding_deployment_name = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLClient\n",
    "\n",
    "Initalize MlClient to interact with resources in your Azure AI Studio\n",
    "Please make sure you have connections for your embedding model and Azure AI Search in this workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "client=MLClient(DefaultAzureCredential(), \n",
    "                subscription_id=subscription_id,\n",
    "                resource_group_name=resource_group,\n",
    "                workspace_name=workspace)\n",
    "\n",
    "# client=MLClient.from_config(DefaultAzureCredential(), path=\"./config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input types\n",
    "\n",
    "You can build index from the following four types of inputs:\n",
    "1. Local files/folders\n",
    "2. Github repo\n",
    "3. Azure Storages\n",
    "4. Existing AI Search index\n",
    "\n",
    "Examples of various data sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input sources\n",
    "from azure.ai.ml.entities._indexes import LocalSource, AISearchSource, GitSource\n",
    "\n",
    "# Local source\n",
    "input_source_local = LocalSource(input_data=\"product-info/\")\n",
    "\n",
    "# Github repo\n",
    "input_source_git = GitSource(git_url=\"https://github.com/rust-lang/book.git\", git_branch_name=\"main\", git_connection_id=\"\")\n",
    "\n",
    "# Azure Storage\n",
    "input_source_subscription = \"<subscription>\"\n",
    "input_source_resource_group = \"<resource_group>\"\n",
    "input_source_workspace = \"<workspace>\"\n",
    "input_source_datastore = \"<datastore_name>\"\n",
    "input_source_path = \"path\"\n",
    "input_source_urls=f\"azureml://subscriptions/{input_source_subscription}/resourcegroups/{input_source_resource_group}/workspaces/{input_source_workspace}/datastores/{input_source_datastore}/paths/{input_source_path}\"\n",
    "\n",
    "# Existing AI Search index\n",
    "input_source_ai_search = AISearchSource(ai_search_index_name=\"remote_index\",\n",
    "                                        ai_search_index_content_key=\"content\",\n",
    "                                        ai_search_index_embedding_key=\"contentVector\",\n",
    "                                        ai_search_index_title_key=\"title\",\n",
    "                                        ai_search_index_metadata_key=\"meta_json_string\",\n",
    "                                        ai_search_index_connection_id=ai_search_connection.id\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connections\n",
    "\n",
    "The following connection types are supported:\n",
    "1. Entra id connections\n",
    "2. Api key based connections\n",
    "3. Connections to serverless models (cohere)\n",
    "\n",
    "Please make sure you have deployments for the embedding model in this workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities._indexes import ModelConfiguration\n",
    "## aoai and acs connections - entra id\n",
    "aoai_connection = client.connections.get(\"<aoai_entra_id_connection>\")\n",
    "ai_search_connection = client.connections.get(\"<search_entra_id_connection>>\")\n",
    "embeddings_model_config = ModelConfiguration.from_connection(aoai_connection, \n",
    "                                                             model_name=\"text-embedding-ada-002\",\n",
    "                                                             deployment_name=\"text-embedding-ada-002\")\n",
    "\n",
    "## aoai and acs connections\n",
    "aoai_connection = client.connections.get(\"<aoai_connection>\", populate_secrets=True)\n",
    "ai_search_connection = client.connections.get(\"<search_connection>\")\n",
    "# workaround for connections.get() not returning api_key\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"<aoai_api_key>\"\n",
    "embeddings_model_config = ModelConfiguration.from_connection(aoai_connection, \n",
    "                                                             model_name=\"text-embedding-ada-002\",\n",
    "                                                             deployment_name=\"text-embedding-ada-002\")\n",
    "\n",
    "## cohere\n",
    "cohere_serverless_connection = client.connections.get(\"<cohere_severless>\")\n",
    "ai_search_connection = client.connections.get(\"<search_connection>\")\n",
    "embeddings_model_config = ModelConfiguration.from_connection(cohere_serverless_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build index on cloud\n",
    "\n",
    "You can change the input_source to anything listed above. input_source_credential is needed for Azure Storage input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities._credentials import UserIdentityConfiguration\n",
    "from azure.ai.ml.entities._indexes import AzureAISearchConfig\n",
    "\n",
    "client.indexes.build_index(\n",
    "    name=index_name, # name of your index\n",
    "    embeddings_model_config=embeddings_model_config,\n",
    "    input_source=input_source_local, \n",
    "    # input_source_credential=UserIdentityConfiguration(), # user specified identity used to access the data.\n",
    "    index_config=AzureAISearchConfig(\n",
    "        ai_search_index_name=index_name,  # the name of the index store in AI search service\n",
    "        ai_search_connection_id=ai_search_connection.id, # AI Search connection details\n",
    "    ),\n",
    "    tokens_per_chunk = 800, # Optional field - Maximum number of tokens per chunk\n",
    "    token_overlap_across_chunks = 0, # Optional field - Number of tokens to overlap between chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the index object once the job is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_index=client.indexes.get(name=index_name, label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consume the index as a langchain retriever\n",
    "\n",
    "Known issue this is broken right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = ml_index.as_langchain_retriever()\n",
    "# retriever.get_relevant_documents(\"which tent is the most waterproof?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workaround: specify the storage uri of the MLIndex file and consume it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"azureml://subscriptions/f375b912-331c-4fc5-8e9f-2d7205e3e036/resourcegroups/rg-jingyizhuai/workspaces/jingyizhu-project-2/datastores/workspaceblobstore/paths/indexes/remote-local-02/3a76509a-600b-4c65-a593-1b0944fa68ff/\"\n",
    "from azureml.rag.mlindex import MLIndex as InternalMLIndex\n",
    "retriever = InternalMLIndex(str(path)).as_langchain_retriever()\n",
    "retriever.get_relevant_documents(\"which tent is the most waterproof?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
